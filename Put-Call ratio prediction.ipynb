{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stock Index', '10/Aug', '11/Aug', '12/Aug', '13/Aug', '14/Aug', '15/Aug']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Index</th>\n",
       "      <th>10/Aug</th>\n",
       "      <th>11/Aug</th>\n",
       "      <th>12/Aug</th>\n",
       "      <th>13/Aug</th>\n",
       "      <th>14/Aug</th>\n",
       "      <th>15/Aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AC3235</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.983224</td>\n",
       "      <td>0.90121088</td>\n",
       "      <td>0.8983682944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AC3236</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.85448</td>\n",
       "      <td>1.0866448</td>\n",
       "      <td>1.017042176</td>\n",
       "      <td>1.02925765888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC3237</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.95024</td>\n",
       "      <td>1.2073024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.18196191744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AC3238</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.16912</td>\n",
       "      <td>1.4830912</td>\n",
       "      <td>1.461062144</td>\n",
       "      <td>1.53100022272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AC3239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1.27856</td>\n",
       "      <td>1.6209856</td>\n",
       "      <td>1.615503872</td>\n",
       "      <td>1.70551937536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Index 10/Aug 11/Aug   12/Aug     13/Aug       14/Aug         15/Aug\n",
       "2      AC3235    0.8   0.66   0.7724   0.983224   0.90121088   0.8983682944\n",
       "3      AC3236   0.86  0.732  0.85448  1.0866448  1.017042176  1.02925765888\n",
       "4      AC3237   0.93  0.816  0.95024  1.2073024          NaN  1.18196191744\n",
       "5      AC3238   1.09  1.008  1.16912  1.4830912  1.461062144  1.53100022272\n",
       "6      AC3239    NaN  1.104  1.27856  1.6209856  1.615503872  1.70551937536"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Test_2.csv',header=None)\n",
    "data = df.drop(df.index[[0,1]])\n",
    "col_names = list(df.iloc[1,1:])\n",
    "col_names.insert(0,'Stock Index')\n",
    "print(col_names)\n",
    "data.columns = col_names\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10/Aug</th>\n",
       "      <th>11/Aug</th>\n",
       "      <th>12/Aug</th>\n",
       "      <th>13/Aug</th>\n",
       "      <th>14/Aug</th>\n",
       "      <th>15/Aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.983224</td>\n",
       "      <td>0.90121088</td>\n",
       "      <td>0.8983682944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.85448</td>\n",
       "      <td>1.0866448</td>\n",
       "      <td>1.017042176</td>\n",
       "      <td>1.02925765888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.95024</td>\n",
       "      <td>1.2073024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.18196191744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.09</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.16912</td>\n",
       "      <td>1.4830912</td>\n",
       "      <td>1.461062144</td>\n",
       "      <td>1.53100022272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1.27856</td>\n",
       "      <td>1.6209856</td>\n",
       "      <td>1.615503872</td>\n",
       "      <td>1.70551937536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  10/Aug 11/Aug   12/Aug     13/Aug       14/Aug         15/Aug\n",
       "2    0.8   0.66   0.7724   0.983224   0.90121088   0.8983682944\n",
       "3   0.86  0.732  0.85448  1.0866448  1.017042176  1.02925765888\n",
       "4   0.93  0.816  0.95024  1.2073024          NaN  1.18196191744\n",
       "5   1.09  1.008  1.16912  1.4830912  1.461062144  1.53100022272\n",
       "6    NaN  1.104  1.27856  1.6209856  1.615503872  1.70551937536"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Stock Index'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8        0.66       0.7724     0.983224   0.90121088 0.89836829]\n",
      " [0.86       0.732      0.85448    1.0866448  1.01704218 1.02925766]\n",
      " [0.93       0.816      0.95024    1.2073024  1.15217888 1.18196192]\n",
      " ...\n",
      " [0.67       0.504      0.59456    0.7591456  0.65024307 0.61477467]\n",
      " [0.79       0.648      0.75872    0.9659872  0.88190566 0.8765534 ]\n",
      " [0.74       0.588      0.69032    0.8798032  0.78537958 0.76747893]]\n",
      "1.96729810432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "data = imp.fit_transform(data)\n",
    "print(data)\n",
    "print(np.amax(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3331, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:-1]\n",
    "y = data[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset into train and test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2331, 5)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 5, 128)            66560     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 329,857\n",
      "Trainable params: 329,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences=True,input_shape=(5,1)))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2331 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "2331/2331 [==============================] - 7s 3ms/sample - loss: 0.3160 - mse: 0.3160 - mae: 0.4128 - val_loss: 0.0494 - val_mse: 0.0494 - val_mae: 0.1853\n",
      "Epoch 2/100\n",
      "2331/2331 [==============================] - 1s 422us/sample - loss: 0.0241 - mse: 0.0241 - mae: 0.1260 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0642\n",
      "Epoch 3/100\n",
      "2331/2331 [==============================] - 1s 283us/sample - loss: 0.0021 - mse: 0.0021 - mae: 0.0334 - val_loss: 7.7874e-04 - val_mse: 7.7874e-04 - val_mae: 0.0234\n",
      "Epoch 4/100\n",
      "2331/2331 [==============================] - 1s 303us/sample - loss: 8.0443e-04 - mse: 8.0443e-04 - mae: 0.0243 - val_loss: 7.7654e-04 - val_mse: 7.7654e-04 - val_mae: 0.0215\n",
      "Epoch 5/100\n",
      "2331/2331 [==============================] - 1s 310us/sample - loss: 6.9693e-04 - mse: 6.9693e-04 - mae: 0.0222 - val_loss: 6.1906e-04 - val_mse: 6.1906e-04 - val_mae: 0.0207\n",
      "Epoch 6/100\n",
      "2331/2331 [==============================] - 1s 304us/sample - loss: 6.2491e-04 - mse: 6.2491e-04 - mae: 0.0211 - val_loss: 6.7138e-04 - val_mse: 6.7138e-04 - val_mae: 0.0226\n",
      "Epoch 7/100\n",
      "2331/2331 [==============================] - 1s 293us/sample - loss: 5.7186e-04 - mse: 5.7186e-04 - mae: 0.0199 - val_loss: 4.8323e-04 - val_mse: 4.8323e-04 - val_mae: 0.0188\n",
      "Epoch 8/100\n",
      "2331/2331 [==============================] - 1s 311us/sample - loss: 4.7298e-04 - mse: 4.7298e-04 - mae: 0.0183 - val_loss: 4.2135e-04 - val_mse: 4.2135e-04 - val_mae: 0.0163\n",
      "Epoch 9/100\n",
      "2331/2331 [==============================] - 1s 326us/sample - loss: 3.9969e-04 - mse: 3.9969e-04 - mae: 0.0167 - val_loss: 3.3502e-04 - val_mse: 3.3502e-04 - val_mae: 0.0152\n",
      "Epoch 10/100\n",
      "2331/2331 [==============================] - 1s 310us/sample - loss: 3.1816e-04 - mse: 3.1816e-04 - mae: 0.0150 - val_loss: 3.1483e-04 - val_mse: 3.1483e-04 - val_mae: 0.0137\n",
      "Epoch 11/100\n",
      "2331/2331 [==============================] - 1s 292us/sample - loss: 2.6312e-04 - mse: 2.6312e-04 - mae: 0.0135 - val_loss: 2.1109e-04 - val_mse: 2.1109e-04 - val_mae: 0.0120\n",
      "Epoch 12/100\n",
      "2331/2331 [==============================] - 1s 311us/sample - loss: 1.9928e-04 - mse: 1.9928e-04 - mae: 0.0118 - val_loss: 1.6249e-04 - val_mse: 1.6249e-04 - val_mae: 0.0107\n",
      "Epoch 13/100\n",
      "2331/2331 [==============================] - 1s 313us/sample - loss: 1.5031e-04 - mse: 1.5031e-04 - mae: 0.0102 - val_loss: 1.1937e-04 - val_mse: 1.1937e-04 - val_mae: 0.0089\n",
      "Epoch 14/100\n",
      "2331/2331 [==============================] - 1s 298us/sample - loss: 1.0660e-04 - mse: 1.0660e-04 - mae: 0.0086 - val_loss: 8.8451e-05 - val_mse: 8.8451e-05 - val_mae: 0.0073\n",
      "Epoch 15/100\n",
      "2331/2331 [==============================] - 1s 309us/sample - loss: 7.5935e-05 - mse: 7.5935e-05 - mae: 0.0071 - val_loss: 5.9421e-05 - val_mse: 5.9421e-05 - val_mae: 0.0063\n",
      "Epoch 16/100\n",
      "2331/2331 [==============================] - 1s 316us/sample - loss: 5.2211e-05 - mse: 5.2211e-05 - mae: 0.0059 - val_loss: 4.2923e-05 - val_mse: 4.2923e-05 - val_mae: 0.0054\n",
      "Epoch 17/100\n",
      "2331/2331 [==============================] - 1s 308us/sample - loss: 3.6289e-05 - mse: 3.6289e-05 - mae: 0.0048 - val_loss: 3.0078e-05 - val_mse: 3.0078e-05 - val_mae: 0.0045\n",
      "Epoch 18/100\n",
      "2331/2331 [==============================] - 1s 314us/sample - loss: 2.3441e-05 - mse: 2.3441e-05 - mae: 0.0039 - val_loss: 2.0164e-05 - val_mse: 2.0164e-05 - val_mae: 0.0035\n",
      "Epoch 19/100\n",
      "2331/2331 [==============================] - 1s 311us/sample - loss: 1.6781e-05 - mse: 1.6781e-05 - mae: 0.0032 - val_loss: 1.4234e-05 - val_mse: 1.4234e-05 - val_mae: 0.0029\n",
      "Epoch 20/100\n",
      "2331/2331 [==============================] - 1s 300us/sample - loss: 1.2285e-05 - mse: 1.2285e-05 - mae: 0.0028 - val_loss: 1.1678e-05 - val_mse: 1.1678e-05 - val_mae: 0.0028\n",
      "Epoch 21/100\n",
      "2331/2331 [==============================] - 1s 304us/sample - loss: 1.0102e-05 - mse: 1.0102e-05 - mae: 0.0026 - val_loss: 9.1374e-06 - val_mse: 9.1374e-06 - val_mae: 0.0026\n",
      "Epoch 22/100\n",
      "2331/2331 [==============================] - 1s 344us/sample - loss: 9.3026e-06 - mse: 9.3026e-06 - mae: 0.0025 - val_loss: 8.8408e-06 - val_mse: 8.8408e-06 - val_mae: 0.0025\n",
      "Epoch 23/100\n",
      "2331/2331 [==============================] - 1s 314us/sample - loss: 8.6025e-06 - mse: 8.6025e-06 - mae: 0.0024 - val_loss: 8.2367e-06 - val_mse: 8.2367e-06 - val_mae: 0.0025\n",
      "Epoch 24/100\n",
      "2331/2331 [==============================] - 1s 350us/sample - loss: 8.0891e-06 - mse: 8.0891e-06 - mae: 0.0024 - val_loss: 8.3852e-06 - val_mse: 8.3852e-06 - val_mae: 0.0025\n",
      "Epoch 25/100\n",
      "2331/2331 [==============================] - 1s 318us/sample - loss: 8.5972e-06 - mse: 8.5972e-06 - mae: 0.0025 - val_loss: 7.6027e-06 - val_mse: 7.6027e-06 - val_mae: 0.0024\n",
      "Epoch 26/100\n",
      "2331/2331 [==============================] - 1s 283us/sample - loss: 7.5528e-06 - mse: 7.5528e-06 - mae: 0.0023 - val_loss: 7.6365e-06 - val_mse: 7.6365e-06 - val_mae: 0.0024\n",
      "Epoch 27/100\n",
      "2331/2331 [==============================] - 1s 300us/sample - loss: 7.4129e-06 - mse: 7.4129e-06 - mae: 0.0023 - val_loss: 7.1027e-06 - val_mse: 7.1027e-06 - val_mae: 0.0023\n",
      "Epoch 28/100\n",
      "2331/2331 [==============================] - 1s 306us/sample - loss: 7.2870e-06 - mse: 7.2870e-06 - mae: 0.0023 - val_loss: 6.8306e-06 - val_mse: 6.8306e-06 - val_mae: 0.0023\n",
      "Epoch 29/100\n",
      "2331/2331 [==============================] - 1s 332us/sample - loss: 7.3207e-06 - mse: 7.3207e-06 - mae: 0.0023 - val_loss: 7.4220e-06 - val_mse: 7.4220e-06 - val_mae: 0.0023\n",
      "Epoch 30/100\n",
      "2331/2331 [==============================] - 1s 311us/sample - loss: 7.6393e-06 - mse: 7.6393e-06 - mae: 0.0023 - val_loss: 7.0528e-06 - val_mse: 7.0528e-06 - val_mae: 0.0023\n",
      "Epoch 31/100\n",
      "2331/2331 [==============================] - 1s 304us/sample - loss: 9.0826e-06 - mse: 9.0826e-06 - mae: 0.0025 - val_loss: 7.6571e-06 - val_mse: 7.6571e-06 - val_mae: 0.0024\n",
      "Epoch 32/100\n",
      "2331/2331 [==============================] - 1s 300us/sample - loss: 6.9961e-06 - mse: 6.9961e-06 - mae: 0.0023 - val_loss: 7.8690e-06 - val_mse: 7.8690e-06 - val_mae: 0.0023\n",
      "Epoch 33/100\n",
      "2331/2331 [==============================] - 1s 302us/sample - loss: 6.8245e-06 - mse: 6.8245e-06 - mae: 0.0022 - val_loss: 9.0742e-06 - val_mse: 9.0742e-06 - val_mae: 0.0024\n",
      "Epoch 34/100\n",
      "2331/2331 [==============================] - 1s 313us/sample - loss: 9.0251e-06 - mse: 9.0251e-06 - mae: 0.0024 - val_loss: 6.5996e-06 - val_mse: 6.5996e-06 - val_mae: 0.0022\n",
      "Epoch 35/100\n",
      "2331/2331 [==============================] - 1s 331us/sample - loss: 7.1365e-06 - mse: 7.1365e-06 - mae: 0.0023 - val_loss: 9.3356e-06 - val_mse: 9.3356e-06 - val_mae: 0.0025\n",
      "Epoch 36/100\n",
      "2331/2331 [==============================] - 1s 355us/sample - loss: 7.0997e-06 - mse: 7.0997e-06 - mae: 0.0022 - val_loss: 7.8970e-06 - val_mse: 7.8970e-06 - val_mae: 0.0024\n",
      "Epoch 37/100\n",
      "2331/2331 [==============================] - 1s 362us/sample - loss: 7.8432e-06 - mse: 7.8432e-06 - mae: 0.0023 - val_loss: 6.0553e-06 - val_mse: 6.0553e-06 - val_mae: 0.0022\n",
      "Epoch 38/100\n",
      "2331/2331 [==============================] - 1s 374us/sample - loss: 7.7918e-06 - mse: 7.7918e-06 - mae: 0.0023 - val_loss: 5.8720e-06 - val_mse: 5.8720e-06 - val_mae: 0.0021\n",
      "Epoch 39/100\n",
      "2331/2331 [==============================] - 1s 360us/sample - loss: 6.5629e-06 - mse: 6.5629e-06 - mae: 0.0022 - val_loss: 6.2550e-06 - val_mse: 6.2550e-06 - val_mae: 0.0022\n",
      "Epoch 40/100\n",
      "2331/2331 [==============================] - 1s 384us/sample - loss: 6.3854e-06 - mse: 6.3854e-06 - mae: 0.0021 - val_loss: 5.7744e-06 - val_mse: 5.7744e-06 - val_mae: 0.0021\n",
      "Epoch 41/100\n",
      "2331/2331 [==============================] - 1s 357us/sample - loss: 6.1993e-06 - mse: 6.1993e-06 - mae: 0.0021 - val_loss: 9.4683e-06 - val_mse: 9.4683e-06 - val_mae: 0.0024\n",
      "Epoch 42/100\n",
      "2331/2331 [==============================] - 1s 351us/sample - loss: 7.1384e-06 - mse: 7.1384e-06 - mae: 0.0022 - val_loss: 6.0645e-06 - val_mse: 6.0645e-06 - val_mae: 0.0022\n",
      "Epoch 43/100\n",
      "2331/2331 [==============================] - 1s 383us/sample - loss: 6.5582e-06 - mse: 6.5582e-06 - mae: 0.0022 - val_loss: 5.6399e-06 - val_mse: 5.6399e-06 - val_mae: 0.0021\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2331/2331 [==============================] - 1s 365us/sample - loss: 5.8359e-06 - mse: 5.8359e-06 - mae: 0.0021 - val_loss: 5.6587e-06 - val_mse: 5.6587e-06 - val_mae: 0.0020\n",
      "Epoch 45/100\n",
      "2331/2331 [==============================] - 1s 346us/sample - loss: 6.9123e-06 - mse: 6.9123e-06 - mae: 0.0022 - val_loss: 6.7579e-06 - val_mse: 6.7579e-06 - val_mae: 0.0021\n",
      "Epoch 46/100\n",
      "2331/2331 [==============================] - 1s 336us/sample - loss: 7.5949e-06 - mse: 7.5949e-06 - mae: 0.0022 - val_loss: 5.9681e-06 - val_mse: 5.9681e-06 - val_mae: 0.0020\n",
      "Epoch 47/100\n",
      "2331/2331 [==============================] - 1s 363us/sample - loss: 7.1542e-06 - mse: 7.1542e-06 - mae: 0.0022 - val_loss: 5.9689e-06 - val_mse: 5.9689e-06 - val_mae: 0.0020\n",
      "Epoch 48/100\n",
      "2331/2331 [==============================] - 1s 357us/sample - loss: 6.6913e-06 - mse: 6.6913e-06 - mae: 0.0021 - val_loss: 5.3219e-06 - val_mse: 5.3219e-06 - val_mae: 0.0020\n",
      "Epoch 49/100\n",
      "2331/2331 [==============================] - 1s 304us/sample - loss: 7.3059e-06 - mse: 7.3059e-06 - mae: 0.0022 - val_loss: 4.8143e-06 - val_mse: 4.8143e-06 - val_mae: 0.0019\n",
      "Epoch 50/100\n",
      "2331/2331 [==============================] - 1s 337us/sample - loss: 6.0866e-06 - mse: 6.0866e-06 - mae: 0.0020 - val_loss: 6.1681e-06 - val_mse: 6.1681e-06 - val_mae: 0.0021\n",
      "Epoch 51/100\n",
      "2331/2331 [==============================] - 1s 362us/sample - loss: 8.0022e-06 - mse: 8.0022e-06 - mae: 0.0023 - val_loss: 1.1385e-05 - val_mse: 1.1385e-05 - val_mae: 0.0026\n",
      "Epoch 52/100\n",
      "2331/2331 [==============================] - 1s 322us/sample - loss: 8.4908e-06 - mse: 8.4908e-06 - mae: 0.0023 - val_loss: 4.9976e-06 - val_mse: 4.9976e-06 - val_mae: 0.0019\n",
      "Epoch 53/100\n",
      "2331/2331 [==============================] - 1s 337us/sample - loss: 5.8130e-06 - mse: 5.8130e-06 - mae: 0.0020 - val_loss: 4.6344e-06 - val_mse: 4.6344e-06 - val_mae: 0.0018\n",
      "Epoch 54/100\n",
      "2331/2331 [==============================] - 1s 360us/sample - loss: 6.2427e-06 - mse: 6.2427e-06 - mae: 0.0020 - val_loss: 4.9634e-06 - val_mse: 4.9634e-06 - val_mae: 0.0019\n",
      "Epoch 55/100\n",
      "2331/2331 [==============================] - 1s 358us/sample - loss: 7.3119e-06 - mse: 7.3119e-06 - mae: 0.0022 - val_loss: 6.8021e-06 - val_mse: 6.8021e-06 - val_mae: 0.0021\n",
      "Epoch 56/100\n",
      "2331/2331 [==============================] - 1s 385us/sample - loss: 6.9999e-06 - mse: 6.9999e-06 - mae: 0.0021 - val_loss: 4.3349e-06 - val_mse: 4.3349e-06 - val_mae: 0.0018\n",
      "Epoch 57/100\n",
      "2331/2331 [==============================] - 1s 346us/sample - loss: 4.6406e-06 - mse: 4.6406e-06 - mae: 0.0018 - val_loss: 7.4204e-06 - val_mse: 7.4204e-06 - val_mae: 0.0022\n",
      "Epoch 58/100\n",
      "2331/2331 [==============================] - 1s 349us/sample - loss: 6.9995e-06 - mse: 6.9995e-06 - mae: 0.0021 - val_loss: 6.2368e-06 - val_mse: 6.2368e-06 - val_mae: 0.0020\n",
      "Epoch 59/100\n",
      "2331/2331 [==============================] - 1s 349us/sample - loss: 8.9591e-06 - mse: 8.9591e-06 - mae: 0.0024 - val_loss: 9.7584e-06 - val_mse: 9.7584e-06 - val_mae: 0.0025\n",
      "Epoch 60/100\n",
      "2331/2331 [==============================] - 1s 339us/sample - loss: 5.1944e-06 - mse: 5.1944e-06 - mae: 0.0019 - val_loss: 5.5815e-06 - val_mse: 5.5815e-06 - val_mae: 0.0019\n",
      "Epoch 61/100\n",
      "2331/2331 [==============================] - 1s 341us/sample - loss: 4.7686e-06 - mse: 4.7686e-06 - mae: 0.0018 - val_loss: 4.6056e-06 - val_mse: 4.6056e-06 - val_mae: 0.0018\n",
      "Epoch 62/100\n",
      "2331/2331 [==============================] - 1s 339us/sample - loss: 5.1192e-06 - mse: 5.1192e-06 - mae: 0.0018 - val_loss: 6.2687e-06 - val_mse: 6.2687e-06 - val_mae: 0.0020\n",
      "Epoch 63/100\n",
      "2331/2331 [==============================] - 1s 348us/sample - loss: 5.4527e-06 - mse: 5.4527e-06 - mae: 0.0019 - val_loss: 1.2012e-05 - val_mse: 1.2012e-05 - val_mae: 0.0030\n",
      "Epoch 64/100\n",
      "2331/2331 [==============================] - 1s 327us/sample - loss: 6.8340e-06 - mse: 6.8340e-06 - mae: 0.0021 - val_loss: 4.0649e-06 - val_mse: 4.0649e-06 - val_mae: 0.0016\n",
      "Epoch 65/100\n",
      "2331/2331 [==============================] - 1s 347us/sample - loss: 6.6837e-06 - mse: 6.6837e-06 - mae: 0.0021 - val_loss: 3.3505e-06 - val_mse: 3.3505e-06 - val_mae: 0.0016\n",
      "Epoch 66/100\n",
      "2331/2331 [==============================] - 1s 346us/sample - loss: 3.7897e-06 - mse: 3.7897e-06 - mae: 0.0016 - val_loss: 6.4852e-06 - val_mse: 6.4852e-06 - val_mae: 0.0021\n",
      "Epoch 67/100\n",
      "2331/2331 [==============================] - 1s 354us/sample - loss: 4.7991e-06 - mse: 4.7991e-06 - mae: 0.0018 - val_loss: 2.8038e-06 - val_mse: 2.8038e-06 - val_mae: 0.0014\n",
      "Epoch 68/100\n",
      "2331/2331 [==============================] - 1s 344us/sample - loss: 5.3446e-06 - mse: 5.3446e-06 - mae: 0.0018 - val_loss: 6.5718e-06 - val_mse: 6.5718e-06 - val_mae: 0.0020\n",
      "Epoch 69/100\n",
      "2331/2331 [==============================] - 1s 455us/sample - loss: 3.8637e-06 - mse: 3.8637e-06 - mae: 0.0016 - val_loss: 6.8879e-06 - val_mse: 6.8879e-06 - val_mae: 0.0022\n",
      "Epoch 70/100\n",
      "2331/2331 [==============================] - 1s 353us/sample - loss: 5.4942e-06 - mse: 5.4942e-06 - mae: 0.0019 - val_loss: 9.4297e-06 - val_mse: 9.4297e-06 - val_mae: 0.0027\n",
      "Epoch 71/100\n",
      "2331/2331 [==============================] - 1s 351us/sample - loss: 6.6342e-06 - mse: 6.6342e-06 - mae: 0.0021 - val_loss: 3.7578e-06 - val_mse: 3.7578e-06 - val_mae: 0.0015\n",
      "Epoch 72/100\n",
      "2331/2331 [==============================] - 1s 335us/sample - loss: 3.0354e-06 - mse: 3.0354e-06 - mae: 0.0014 - val_loss: 5.0390e-06 - val_mse: 5.0390e-06 - val_mae: 0.0018\n",
      "Epoch 73/100\n",
      "2331/2331 [==============================] - 1s 352us/sample - loss: 3.7032e-06 - mse: 3.7032e-06 - mae: 0.0016 - val_loss: 2.1125e-06 - val_mse: 2.1125e-06 - val_mae: 0.0012\n",
      "Epoch 74/100\n",
      "2331/2331 [==============================] - 1s 356us/sample - loss: 3.0785e-06 - mse: 3.0785e-06 - mae: 0.0014 - val_loss: 5.4906e-06 - val_mse: 5.4906e-06 - val_mae: 0.0018\n",
      "Epoch 75/100\n",
      "2331/2331 [==============================] - 1s 353us/sample - loss: 6.0707e-06 - mse: 6.0707e-06 - mae: 0.0019 - val_loss: 2.0143e-06 - val_mse: 2.0143e-06 - val_mae: 0.0012\n",
      "Epoch 76/100\n",
      "2331/2331 [==============================] - 1s 352us/sample - loss: 3.3701e-06 - mse: 3.3701e-06 - mae: 0.0015 - val_loss: 1.7770e-06 - val_mse: 1.7770e-06 - val_mae: 0.0012\n",
      "Epoch 77/100\n",
      "2331/2331 [==============================] - 1s 340us/sample - loss: 1.1471e-05 - mse: 1.1471e-05 - mae: 0.0025 - val_loss: 1.0126e-05 - val_mse: 1.0126e-05 - val_mae: 0.0028\n",
      "Epoch 78/100\n",
      "2331/2331 [==============================] - 1s 351us/sample - loss: 5.8930e-06 - mse: 5.8930e-06 - mae: 0.0019 - val_loss: 2.1588e-06 - val_mse: 2.1588e-06 - val_mae: 0.0012\n",
      "Epoch 79/100\n",
      "2331/2331 [==============================] - 1s 367us/sample - loss: 2.7352e-06 - mse: 2.7352e-06 - mae: 0.0013 - val_loss: 8.6263e-06 - val_mse: 8.6263e-06 - val_mae: 0.0026\n",
      "Epoch 80/100\n",
      "2331/2331 [==============================] - 1s 327us/sample - loss: 6.7354e-05 - mse: 6.7354e-05 - mae: 0.0057 - val_loss: 5.8506e-05 - val_mse: 5.8506e-05 - val_mae: 0.0073\n",
      "Epoch 81/100\n",
      "2331/2331 [==============================] - 1s 353us/sample - loss: 2.4558e-04 - mse: 2.4558e-04 - mae: 0.0127 - val_loss: 3.6865e-06 - val_mse: 3.6865e-06 - val_mae: 0.0017\n",
      "Epoch 82/100\n",
      "2331/2331 [==============================] - 1s 334us/sample - loss: 6.4451e-06 - mse: 6.4451e-06 - mae: 0.0021 - val_loss: 2.0977e-06 - val_mse: 2.0977e-06 - val_mae: 0.0012\n",
      "Epoch 83/100\n",
      "2331/2331 [==============================] - 1s 334us/sample - loss: 5.5112e-06 - mse: 5.5112e-06 - mae: 0.0018 - val_loss: 1.0557e-05 - val_mse: 1.0557e-05 - val_mae: 0.0029\n",
      "Epoch 84/100\n",
      "2331/2331 [==============================] - 1s 356us/sample - loss: 1.0908e-05 - mse: 1.0908e-05 - mae: 0.0027 - val_loss: 7.7689e-05 - val_mse: 7.7689e-05 - val_mae: 0.0084\n",
      "Epoch 85/100\n",
      "2331/2331 [==============================] - 1s 365us/sample - loss: 3.0709e-05 - mse: 3.0709e-05 - mae: 0.0045 - val_loss: 1.8449e-06 - val_mse: 1.8449e-06 - val_mae: 9.6423e-04\n",
      "Epoch 86/100\n",
      "2331/2331 [==============================] - 1s 354us/sample - loss: 4.2429e-06 - mse: 4.2429e-06 - mae: 0.0016 - val_loss: 1.3940e-06 - val_mse: 1.3940e-06 - val_mae: 9.5226e-04\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2331/2331 [==============================] - 1s 327us/sample - loss: 7.4564e-06 - mse: 7.4564e-06 - mae: 0.0022 - val_loss: 9.7427e-06 - val_mse: 9.7427e-06 - val_mae: 0.0030\n",
      "Epoch 88/100\n",
      "2331/2331 [==============================] - 1s 334us/sample - loss: 2.9952e-05 - mse: 2.9952e-05 - mae: 0.0045 - val_loss: 1.7352e-05 - val_mse: 1.7352e-05 - val_mae: 0.0040\n",
      "Epoch 89/100\n",
      "2331/2331 [==============================] - 1s 337us/sample - loss: 1.4009e-04 - mse: 1.4009e-04 - mae: 0.0099 - val_loss: 2.0780e-05 - val_mse: 2.0780e-05 - val_mae: 0.0044\n",
      "Epoch 90/100\n",
      "2331/2331 [==============================] - 1s 334us/sample - loss: 1.8552e-05 - mse: 1.8552e-05 - mae: 0.0034 - val_loss: 6.8689e-06 - val_mse: 6.8689e-06 - val_mae: 0.0024\n",
      "Epoch 91/100\n",
      "2331/2331 [==============================] - 1s 322us/sample - loss: 1.8608e-05 - mse: 1.8608e-05 - mae: 0.0032 - val_loss: 1.1707e-06 - val_mse: 1.1707e-06 - val_mae: 8.9247e-04\n",
      "Epoch 92/100\n",
      "2331/2331 [==============================] - 1s 324us/sample - loss: 2.8008e-04 - mse: 2.8008e-04 - mae: 0.0116 - val_loss: 5.6069e-04 - val_mse: 5.6069e-04 - val_mae: 0.0230\n",
      "Epoch 93/100\n",
      "2331/2331 [==============================] - 1s 337us/sample - loss: 5.4113e-04 - mse: 5.4113e-04 - mae: 0.0185 - val_loss: 2.9022e-06 - val_mse: 2.9022e-06 - val_mae: 0.0015\n",
      "Epoch 94/100\n",
      "2331/2331 [==============================] - 1s 334us/sample - loss: 8.8170e-05 - mse: 8.8170e-05 - mae: 0.0079 - val_loss: 1.4814e-05 - val_mse: 1.4814e-05 - val_mae: 0.0037\n",
      "Epoch 95/100\n",
      "2331/2331 [==============================] - 1s 339us/sample - loss: 1.7517e-05 - mse: 1.7517e-05 - mae: 0.0034 - val_loss: 2.9750e-06 - val_mse: 2.9750e-06 - val_mae: 0.0013\n",
      "Epoch 96/100\n",
      "2331/2331 [==============================] - 1s 347us/sample - loss: 1.6076e-06 - mse: 1.6076e-06 - mae: 9.9999e-04 - val_loss: 5.5927e-06 - val_mse: 5.5927e-06 - val_mae: 0.0020\n",
      "Epoch 97/100\n",
      "2331/2331 [==============================] - 1s 345us/sample - loss: 7.4759e-06 - mse: 7.4759e-06 - mae: 0.0022 - val_loss: 1.7251e-05 - val_mse: 1.7251e-05 - val_mae: 0.0038\n",
      "Epoch 98/100\n",
      "2331/2331 [==============================] - 1s 338us/sample - loss: 7.3753e-06 - mse: 7.3753e-06 - mae: 0.0022 - val_loss: 3.0635e-06 - val_mse: 3.0635e-06 - val_mae: 0.0015\n",
      "Epoch 99/100\n",
      "2331/2331 [==============================] - 1s 338us/sample - loss: 4.9042e-06 - mse: 4.9042e-06 - mae: 0.0017 - val_loss: 1.0358e-06 - val_mse: 1.0358e-06 - val_mae: 7.8829e-04\n",
      "Epoch 100/100\n",
      "2331/2331 [==============================] - 1s 347us/sample - loss: 3.0524e-06 - mse: 3.0524e-06 - mae: 0.0013 - val_loss: 2.3416e-06 - val_mse: 2.3416e-06 - val_mae: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1346cc68198>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics=['mse','mae'])\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015886856308180177\n",
      "0.0015302156019993182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_rmse = mean_squared_error(y_train,x_train_pred,squared=False)\n",
    "print(train_rmse)\n",
    "\n",
    "\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_rmse = mean_squared_error(y_test,x_test_pred,squared=False)\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3331, 5)\n",
      "(3331, 5, 1)\n",
      "Put-Call Ratio prediction for 16th Aug \n",
      " [[0.9115969 ]\n",
      " [1.0663332 ]\n",
      " [1.2474985 ]\n",
      " ...\n",
      " [0.57771623]\n",
      " [0.8858633 ]\n",
      " [0.7573909 ]]\n"
     ]
    }
   ],
   "source": [
    "#Put-Call Ratio prediction for 16th Aug\n",
    "\n",
    "x_input = data[:,1:]\n",
    "print(x_input.shape)\n",
    "x_input = x_input.reshape(x_input.shape[0],x_input.shape[1],1)\n",
    "print(x_input.shape)\n",
    "y_input = model.predict(x_input)\n",
    "print('Put-Call Ratio prediction for 16th Aug','\\n',y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Put-Call Ratio.csv\", y_input, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
